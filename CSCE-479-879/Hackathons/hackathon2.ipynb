{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCE 479/879 Hackathon: Dense Layers, Minibatch Training, and Train/Test Splits\n",
    "\n",
    "Written by Eleanor Quint\n",
    "\n",
    "Modified by Mrinal Rawool and Stephen Scott\n",
    "\n",
    "Topics: \n",
    "- Dense layers\n",
    "- Training by minibatch/gradient step and epoch\n",
    "- Splitting the dataset into train/validation\n",
    "\n",
    "This is all setup in a IPython notebook so you can run any code you want to experiment with. Feel free to edit any cell, or add some to run your own code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# We'll start with our library imports...\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np                 # to use numpy arrays\n",
    "import tensorflow as tf            # to specify and run computation graphs\n",
    "import tensorflow_datasets as tfds # to load training data\n",
    "import matplotlib.pyplot as plt    # to visualize data and draw plots\n",
    "from tqdm import tqdm              # to track progress of loops\n",
    "\n",
    "DATA_DIR = './tensorflow-datasets/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the dataset\n",
    "\n",
    "1. Acquire the dataset\n",
    "2. Examine elements, splits\n",
    "3. General rule for model training: train on train_ds, monitor train perf on valid_ds, report final model perf on test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A First Attempt at Classifying MNIST\n",
    "\n",
    "MNIST is a dataset of greyscale 28x28 handwritten digits labelled 0 through 9. We'll use it for a 10-class problem to learn the basics of classification.\n",
    "\n",
    "Let's have a look at the data first. We'll load the data from [Tensorflow Datasets](https://www.tensorflow.org/datasets) and visualize it with matplotlib's `plt.imshow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tfds.load('mnist', data_dir=DATA_DIR, shuffle_files=True) # this loads a dict with the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['test', 'train'])\n"
     ]
    }
   ],
   "source": [
    "print(ds.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops._OptionsDataset'>\n"
     ]
    }
   ],
   "source": [
    "print(type(ds['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can create an iterator from each dataset\n",
    "# This one iterates through the train data, shuffling and minibatching by 32\n",
    "train_ds = ds['train'].shuffle(1024).batch(32) \n",
    "# TODO: change 32 to 64 and check the shape of the batch\n",
    "# shuffle(buffer size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Splitting the dataset into train/validation\n",
    "\n",
    "After one epoch of training the loss values drop dramatically and accuracy rises from change (\\~10%) to that of a decent classifier (\\~85-90%). In practice we want to train for many epochs and use the set of parameters which gives the lowest validation error. Unfortunately, we don't know which set of parameters is best because we're training on all the data. Before training, we should split the training dataset into a train set, which will be used for parameter updates, and a validation set, which will not. Then, we can determine which parameters generalise best by calculating the accuracy on the hold-out validation set. The parameters with the highest accuracy on validation will likely generalise the best.\n",
    "\n",
    "The easiest way to do this is with TensorFlow Datasets is to use their string indexing notation when loading the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first 90% of the training data\n",
    "# Use this data for the training loop\n",
    "train = tfds.load('mnist', split='train[:90%]', data_dir=DATA_DIR)\n",
    "\n",
    "# And the last 10%, we'll hold out as the validation set\n",
    "# Notice the python-style indexing, but in a string and with percentages\n",
    "# After the training loop, run another loop over this data without the gradient updates to calculate accuracy\n",
    "validation = tfds.load('mnist', split='train[-10%:]', data_dir=DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (32, 28, 28, 1)\n",
      "label: tf.Tensor([9 3 3 8 6 9 3 9 1 1 6 4 7 1 5 9 8 0 2 3 9 2 4 7 4 6 9 9 5 3 6 4], shape=(32,), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 12:15:38.679981: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Looping through the iterator, each batch is a dict\n",
    "for batch in train_ds:\n",
    "    # The first dimension in the shape is the batch dimension\n",
    "    # The second and third dimensions are height and width\n",
    "    # Being greyscale means that the image has one channel, the last dimension in the shape\n",
    "    print(\"data shape:\", batch['image'].shape)\n",
    "    print(\"label:\", batch['label'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some of the data\n",
    "idx = np.random.randint(batch['image'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x149540fa2910>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAEOCAYAAAApP3VyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZ7UlEQVR4nO3df3DU9b3v8dcSYEXvZmkGk00uMaaXTO0VDwMUoYgQmJIxVxkBO+XqtAfOnM5FCbmXy1AvyL01pwpRriK3DVBLeymMIlxn5McZqJgOJCmDtBjhiNgC3gkYC2kuGd0NSBdCPvePHnZcCZ9ks7uf/ZHnY+b7x37f++PNl/Dmle/ufr4eY4wRAACAI4NS3QAAABhYCB8AAMApwgcAAHCK8AEAAJwifAAAAKcIHwAAwCnCBwAAcIrwAQAAnCJ8AAAApwanuoGv6u7u1vnz5+Xz+eTxeFLdDjAgGWPU2dmpoqIiDRqUGb+jMDuA1IppbpgkWb9+vbn77ruN1+s148aNM01NTX16XGtrq5HExsaWBltra2uyRkTCMTvY2NJj68vcSMqZjx07dmjJkiXasGGDHnjgAb366quqrKzURx99pLvuusv6WJ/PJ0maov+gwRqSjPYA9KJL13RI+yL/HjNBJvUKZLO+/Fv0GJP4C8tNnDhR48aN08aNGyP7vvnNb2r27Nmqra21PjYUCsnv96tcj2qwh/ABpEKXuaYG7VYwGFRubm6q2+mTG7MDQGr1ZW4k/MzH1atX1dzcrOXLl0ftr6io0OHDh2+6fzgcVjgcjtwOhUKJbglAFmJ2AJkr4Z8ku3jxoq5fv66CgoKo/QUFBWpra7vp/rW1tfL7/ZGtuLg40S0ByELMDiBzJe1j7F/9tLkxpsdPoK9YsULBYDCytba2JqslAFmE2QFkroS/7TJixAjl5OTcdJajvb39prMhkuT1euX1ehPdBoAsx+wAMlfCz3wMHTpU48ePV319fdT++vp6TZ48OdEvBwAAMkxSvmq7dOlS/eAHP9C3vvUtffvb39YvfvELffLJJ3ryySeT8XIAACCDJCV8zJs3Tx0dHfrJT36iCxcuaPTo0dq3b59KSkqS8XIAACCDJG159UWLFmnRokXJenoAAJChMuOiDQAAIGsQPgAAgFOEDwAA4BThAwAAOEX4AAAAThE+AACAU4QPAADgFOEDAAA4RfgAAABOET4AAIBThA8AAOAU4QMAADhF+AAAAE4RPgAAgFOEDwAA4BThAwAAOEX4AAAAThE+AACAU4QPAADgFOEDAAA4NTjVDaBnOd8YZa3/cdnX4nr+31a8Yq1X7Fxmrd/zyp+t9a5zrTH3BCB+xcXF1vqSJUviev4f/vCH1vq6deus9fXr11vr7e3tsbaEDMSZDwAA4BThAwAAOEX4AAAAThE+AACAU4QPAADgFOEDAAA4RfgAAABOeYwxJtVNfFkoFJLf71e5HtVgz5BUt5My/2/PN6z1d8e/ltTXH9RLLj12tdta//F3F1jrpvlkrC3BoS5zTQ3arWAwqNzc3FS30yc3ZsdAt23bNmv9e9/7XlJf3+PxWOsdHR3W+pQpU6z106dPx9wT3OrL3Ej4mY+amhp5PJ6oLRAIJPplAABAhkrKCqf33nuvfvvb30Zu5+TkJONlAABABkpK+Bg8eDBnOwAAQI+SEj7OnDmjoqIieb1eTZw4UatXr9bXv/71Hu8bDocVDocjt0OhUDJaApBlmB1A5kr4Zz4mTpyorVu3av/+/dq0aZPa2to0efLkW37IqLa2Vn6/P7L1dlEkAJCYHUAmS3j4qKys1GOPPab77rtP3/nOd7R3715J0pYtW3q8/4oVKxQMBiNbaytXQwXQO2YHkLmS8rbLl91xxx267777dObMmR7rXq9XXq832W0AyDLMDiBzJT18hMNh/fGPf9SDDz6Y7JfKKr8fb/+uvn2VjeQbM9ReDz7/V2v9a/Ps3wG/zvv3QL/MmzfPWk/10k55eXnW+qpVq6z1+fPnW+tffPFFzD3BvYS/7bJs2TI1NjaqpaVFv//97/Xd735XoVCo1x8YAAAwMCT8zMenn36qxx9/XBcvXtSdd96pSZMm6ciRIyopKUn0SwEAgAyU8PCxffv2RD8lAADIIlxYDgAAOEX4AAAAThE+AACAU4QPAADgVNLX+UD/PNs+1l7Pb3bUSf80/J39g8f//p+qrfVR//VIItsBBoz333/fWh871j5bUm3OnDnW+smTJ631mpqaBHaDZOHMBwAAcIrwAQAAnCJ8AAAApwgfAADAKcIHAABwivABAACcInwAAACnCB8AAMApFhlLU4f+aZK1vniFz1rfMLLJWj945TZrvenSPdb6s3cet9Z7M6/8sLXeTC4G+mXZsmXW+nPPPWetP/DAA9b6+fPnrfW//OUv1nq8i5w9/PDD1jqLjGUGJjwAAHCK8AEAAJwifAAAAKcIHwAAwCnCBwAAcIrwAQAAnCJ8AAAAp1jnI00N2/UHa/1c+xhr/Ve/PGut75ltX0dk98H/Y613q9ta781U3ylrvVnfjOv5gYGqsbHRWl+0aJG1/uabb1rrM2fOtNbPnTtnrRtjrPXeBAKBuB6P9MCZDwAA4BThAwAAOEX4AAAAThE+AACAU4QPAADgFOEDAAA4RfgAAABOsc5HhvIc/hdr/Z9n2tcBMR1/TmQ7MVv2y3+01v+tDjvqBBhYPvzwQ2t9ypQp1npnZ2ci24nZ888/n9LXR2LEfOajqalJs2bNUlFRkTwej3bt2hVVN8aopqZGRUVFGjZsmMrLy3Xy5MlE9QsAADJczOHj8uXLGjNmjOrq6nqsr1mzRmvXrlVdXZ2OHj2qQCCgmTNnpjwtAwCA9BDz2y6VlZWqrKzssWaM0bp167Ry5UrNnTtXkrRlyxYVFBRo27ZtWrhw4U2PCYfDCofDkduhUCjWlgAMQMwOIHMl9AOnLS0tamtrU0VFRWSf1+vVtGnTdPhwz+/h19bWyu/3R7bi4uJEtgQgSzE7gMyV0PDR1tYmSSooKIjaX1BQEKl91YoVKxQMBiNba2trIlsCkKWYHUDmSsq3XTweT9RtY8xN+27wer3yer3JaANAFmN2AJkroWc+blzq+KtnOdrb2286GwIAAAamhJ75KC0tVSAQUH19vcaOHStJunr1qhobG/Xiiy8m8qXQi64/n091C1Z3vfUXa/26oz4AROvo6Eh1C1Z79+5NdQtIgJjDx6VLl/Txxx9Hbre0tOj48ePKy8vTXXfdpSVLlmj16tUqKytTWVmZVq9erdtvv11PPPFEQhsHAACZKebw8d5772n69OmR20uXLpUkzZ8/X7/+9a/19NNP68qVK1q0aJE+++wzTZw4Ue+88458Pl/iugYAABkr5vBRXl4uY8wt6x6PRzU1NaqpqYmnLwAAkKW4sBwAAHCK8AEAAJwifAAAAKcIHwAAwKmkrHCK9Nc1Y7y1PsRz3Fq/duvPHEuSJh973FrPO33a/gQA0tL48fbZMWiQ/Xfa7u5ua/3NN9+01j/99FNrHZmBMx8AAMApwgcAAHCK8AEAAJwifAAAAKcIHwAAwCnCBwAAcIrwAQAAnGKdjwFq8IFma/2auW6td8v+XX0A2am52T47elvHw3ZhUgwcnPkAAABOET4AAIBThA8AAOAU4QMAADhF+AAAAE4RPgAAgFOEDwAA4BTrfKBHm0PF1vr83HPW+vp7X7fW/+OWhdZ62fz3rXUA6enMmTPW+qhRo6z1GTNmWOs/+9nPrPXq6mprHemBMx8AAMApwgcAAHCK8AEAAJwifAAAAKcIHwAAwCnCBwAAcIrwAQAAnPIYY0yqm/iyUCgkv9+vcj2qwZ4hqW5n4Lr/Pmt5z87/ndSXn3D07631oufsudk0n0xkOwNOl7mmBu1WMBhUbm5uqtvpkxuzA6l1zz33WOsffvhhUl//jTfesNafe+45a/306dOJbGdA6svciPnMR1NTk2bNmqWioiJ5PB7t2rUrqr5gwQJ5PJ6obdKkSbG+DAAAyFIxh4/Lly9rzJgxqquru+V9HnroIV24cCGy7du3L64mAQBA9oh5efXKykpVVlZa7+P1ehUIBPrdFAAAyF5JubZLQ0OD8vPzNXz4cE2bNk2rVq1Sfn5+j/cNh8MKh8OR26FQKBktAcgyzA4gcyX82y6VlZV6/fXXdeDAAb388ss6evSoZsyYETUkvqy2tlZ+vz+yFRfbL2gGABKzA8hkCQ8f8+bN08MPP6zRo0dr1qxZ+s1vfqPTp09r7969Pd5/xYoVCgaDka21tTXRLQHIQswOIHMl5W2XLyssLFRJScktL7Ps9Xrl9XqT3QaALMPsADJX0sNHR0eHWltbVVhYmOyXQiL94YS1/K3/9V+s9YPV/9Na9w+6zVr/4H77d/Xf2WFfA+alv3/CWvcc/hdrHUD//OlPf7LWn3rqKWv9pz/9qbU+dOhQa/373/++tV5eXm6t9/aFimSvUzJQxBw+Ll26pI8//jhyu6WlRcePH1deXp7y8vJUU1Ojxx57TIWFhTp79qyeeeYZjRgxQnPmzElo4wAAIDPFHD7ee+89TZ8+PXJ76dKlkqT58+dr48aNOnHihLZu3arPP/9chYWFmj59unbs2CGfz5e4rgEAQMaKOXyUl5fLtiL7/v3742oIAABkNy4sBwAAnCJ8AAAApwgfAADAKcIHAABwKunrfCA7Fa05bK1Py/mRtf4/FtjX8Xjs31y0P/+wa9b6L9d8aq13VtxurXd/8YW1DqB/Nm3aZK3n5ORY6z/6kX223H333dZ6b2tOvfLKK9b6I488Yq3f6lIiiMaZDwAA4BThAwAAOEX4AAAAThE+AACAU4QPAADgFOEDAAA4RfgAAABOeYztKnEpEAqF5Pf7Va5HNdgzJNXtIEk+fm2stf6n6b+01rvVHdfr/93m/2yt3/3f343r+TNdl7mmBu1WMBhUbm5uqtvpkxuzA9ltw4YN1vrChQut9Xj/y1u+fLm1/tJLL8X1/NmgL3ODMx8AAMApwgcAAHCK8AEAAJwifAAAAKcIHwAAwCnCBwAAcIrwAQAAnGKdDyTF/315krXePO8Va/12z1BrPd51Ps51XbXWq0seiOv5Mx3rfCBVfvzjH1vrK1eutNYHDx5srcf7X96lS5es9eHDh8f1/NmAdT4AAEDaIXwAAACnCB8AAMApwgcAAHCK8AEAAJwifAAAAKcIHwAAwCn7F6IxYOV8Y5S1PnvXYWv9H3LX9/IK9nU8hnhyrPVrca5OUzr4tvieAECPiouLrfX6+nprvaysLK7XHzTI/jt1d3d8awT5fL64Ho+/ienMR21trSZMmCCfz6f8/HzNnj1bp06dirqPMUY1NTUqKirSsGHDVF5erpMnTya0aQAAkLliCh+NjY2qqqrSkSNHVF9fr66uLlVUVOjy5cuR+6xZs0Zr165VXV2djh49qkAgoJkzZ6qzszPhzQMAgMwT09sub7/9dtTtzZs3Kz8/X83NzZo6daqMMVq3bp1WrlypuXPnSpK2bNmigoICbdu2TQsXLkxc5wAAICPF9YHTYDAoScrLy5MktbS0qK2tTRUVFZH7eL1eTZs2TYcP9/wZgXA4rFAoFLUBQG+YHUDm6nf4MMZo6dKlmjJlikaPHi1JamtrkyQVFBRE3begoCBS+6ra2lr5/f7I1tuHlQBAYnYAmazf4WPx4sX64IMP9MYbb9xU83g8UbeNMTftu2HFihUKBoORrbW1tb8tARhAmB1A5urXV22rq6u1Z88eNTU1aeTIkZH9gUBA0t/OgBQWFkb2t7e333Q25Aav1yuv19ufNgAMYMwOIHPFFD6MMaqurtbOnTvV0NCg0tLSqHppaakCgYDq6+s1duxYSdLVq1fV2NioF198MXFdI26f/+Db1vo/PrPbWp+fe85aj++b9L2v49Ed5yvc2/CfrPV/p2NxPT+QrR555BFr/aWXXrLWR42yryFkTHyL+PS2jke8z79p06a4Ho+/iSl8VFVVadu2bdq9e7d8Pl/kcxx+v1/Dhg2Tx+PRkiVLtHr1apWVlamsrEyrV6/W7bffrieeeCIpfwAAAJBZYgofGzdulCSVl5dH7d+8ebMWLFggSXr66ad15coVLVq0SJ999pkmTpyod955h1XhAACApH687dIbj8ejmpoa1dTU9LcnAACQxbiwHAAAcIrwAQAAnCJ8AAAApwgfAADAKcIHAABwql8rnCLzBUf1vNz9Df+Qa1+qOt5FxOJ1LGzPzU/8c5W1/o3/dtxaT/WfD0hXZWVlcdXjXeQrXh0dHdb6q6++aq0///zziWxnwOLMBwAAcIrwAQAAnCJ8AAAApwgfAADAKcIHAABwivABAACcInwAAACnWOdjgMo/1pXqFqweeGaxtX5nw6fWetm5I9Y663gA/fP++++nugWrOXPmWOtHjthnQ3t7eyLbwS1w5gMAADhF+AAAAE4RPgAAgFOEDwAA4BThAwAAOEX4AAAAThE+AACAU6zzMUAN2/UHa/2RXeMdddKzr+ldaz29VykBsldjY6O1npOT46gTZDLOfAAAAKcIHwAAwCnCBwAAcIrwAQAAnCJ8AAAApwgfAADAKcIHAABwKqbwUVtbqwkTJsjn8yk/P1+zZ8/WqVOnou6zYMECeTyeqG3SpEkJbRoAAGSumMJHY2OjqqqqdOTIEdXX16urq0sVFRW6fPly1P0eeughXbhwIbLt27cvoU0DAIDMFdMKp2+//XbU7c2bNys/P1/Nzc2aOnVqZL/X61UgEEhMhwAAIKvEtbx6MBiUJOXl5UXtb2hoUH5+voYPH65p06Zp1apVys/P7/E5wuGwwuFw5HYoFIqnJQADBLMDyFz9/sCpMUZLly7VlClTNHr06Mj+yspKvf766zpw4IBefvllHT16VDNmzIgaEl9WW1srv98f2YqLi/vbEoABhNkBZC6PMcb054FVVVXau3evDh06pJEjR97yfhcuXFBJSYm2b9+uuXPn3lTv6beX4uJiletRDfYM6U9rAOLUZa6pQbsVDAaVm5ub6nZ6dKvZASC1+jI3+vW2S3V1tfbs2aOmpiZr8JCkwsJClZSU6MyZMz3WvV6vvF5vf9oAMIAxO4DMFVP4MMaourpaO3fuVENDg0pLS3t9TEdHh1pbW1VYWNjvJgEAQPaI6TMfVVVVeu2117Rt2zb5fD61tbWpra1NV65ckSRdunRJy5Yt07vvvquzZ8+qoaFBs2bN0ogRIzRnzpyk/AEAAEBmienMx8aNGyVJ5eXlUfs3b96sBQsWKCcnRydOnNDWrVv1+eefq7CwUNOnT9eOHTvk8/kS1jQAAMhcMb/tYjNs2DDt378/roYAAEB249ouAADAKcIHAABwivABAACcInwAAACnCB8AAMApwgcAAHCK8AEAAJwifAAAAKcIHwAAwCnCBwAAcIrwAQAAnCJ8AAAAp2K6sJwLNy5e16Vrkv06dgCSpEvXJPV+Mcl0kkm9AtmsL/8W0y58dHZ2SpIOaV+KOwHQ2dkpv9+f6jb65MbsAJBafZkbHpNmvy50d3fr/Pnz8vl88ng8CoVCKi4uVmtrq3Jzc1PdXkbiGMZvoB1DY4w6OztVVFSkQYMy491ZZkficQzjM9COXyxzI+3OfAwaNEgjR468aX9ubu6A+MtLJo5h/AbSMcyUMx43MDuSh2MYn4F0/Po6NzLjVxoAAJA1CB8AAMCptA8fXq9Xzz77rLxeb6pbyVgcw/hxDDMPf2fx4xjGh+N3a2n3gVMAAJDd0v7MBwAAyC6EDwAA4BThAwAAOEX4AAAAThE+AACAU2kfPjZs2KDS0lLddtttGj9+vH73u9+luqW01dTUpFmzZqmoqEgej0e7du2KqhtjVFNTo6KiIg0bNkzl5eU6efJkappNQ7W1tZowYYJ8Pp/y8/M1e/ZsnTp1Kuo+HMPMwNzoO+ZGfJgb/ZPW4WPHjh1asmSJVq5cqWPHjunBBx9UZWWlPvnkk1S3lpYuX76sMWPGqK6ursf6mjVrtHbtWtXV1eno0aMKBAKaOXMmF+T6V42NjaqqqtKRI0dUX1+vrq4uVVRU6PLly5H7cAzTH3MjNsyN+DA3+smksfvvv988+eSTUfvuueces3z58hR1lDkkmZ07d0Zud3d3m0AgYF544YXIvr/+9a/G7/ebn//85ynoMP21t7cbSaaxsdEYwzHMFMyN/mNuxI+50Tdpe+bj6tWram5uVkVFRdT+iooKHT58OEVdZa6Wlha1tbVFHU+v16tp06ZxPG8hGAxKkvLy8iRxDDMBcyOx+JmPHXOjb9I2fFy8eFHXr19XQUFB1P6CggK1tbWlqKvMdeOYcTz7xhijpUuXasqUKRo9erQkjmEmYG4kFj/zsWFu9N3gVDfQG4/HE3XbGHPTPvQdx7NvFi9erA8++ECHDh26qcYxTH/8HSUWx7NvmBt9l7ZnPkaMGKGcnJybkmF7e/tNCRK9CwQCksTx7IPq6mrt2bNHBw8e1MiRIyP7OYbpj7mRWPzM9x1zIzZpGz6GDh2q8ePHq76+Pmp/fX29Jk+enKKuMldpaakCgUDU8bx69aoaGxs5nv/KGKPFixfrrbfe0oEDB1RaWhpV5ximP+ZGYvEz3zvmRj+l6pOufbF9+3YzZMgQ86tf/cp89NFHZsmSJeaOO+4wZ8+eTXVraamzs9McO3bMHDt2zEgya9euNceOHTPnzp0zxhjzwgsvGL/fb9566y1z4sQJ8/jjj5vCwkITCoVS3Hl6eOqpp4zf7zcNDQ3mwoULke2LL76I3IdjmP6YG7FhbsSHudE/aR0+jDFm/fr1pqSkxAwdOtSMGzcu8vUl3OzgwYNG0k3b/PnzjTF/+8rXs88+awKBgPF6vWbq1KnmxIkTqW06jfR07CSZzZs3R+7DMcwMzI2+Y27Eh7nRPx5jjHF3ngUAAAx0afuZDwAAkJ0IHwAAwCnCBwAAcIrwAQAAnCJ8AAAApwgfAADAKcIHAABwivABAACcInwAAACnCB8AAMApwgcAAHDq/wOSX03pQqOKEwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axarr = plt.subplots(nrows=1, ncols=2, sharey=True)\n",
    "axarr[0].imshow(batch['image'][idx]) # It's colored because matplotlib wants to provide more contrast than just greys\n",
    "axarr[1].imshow(batch['image'][idx], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dense layers\n",
    "\n",
    "The first step to building a simple neural network is to specify layers. The most basic building block is the dense layer (AKA linear layer or fully connected layer), so we'll declare a function that creates the layer. Each dense layer is composed of two variables, the weight matrix `W` and the bias vector `b` as well as a non-linear activation function `a`, to calculate the function `f(x) = a(Wx + b)`.\n",
    "\n",
    "Normally we'll use pre-defined layers, but in this notebook we'll do it ourselves first to better understand what's going on under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(tf.Module):\n",
    "    def __init__(self, output_size, activation=tf.nn.relu):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            - output_size: (int) number of neurons\n",
    "            - activation: (function) non-linear function applied to the output\n",
    "        \"\"\"\n",
    "        self.output_size = output_size\n",
    "        self.activation = activation\n",
    "        self.is_built = False\n",
    "        \n",
    "    def _build(self, x):\n",
    "        data_size = x.shape[-1]\n",
    "        self.W = tf.Variable(tf.random.normal([data_size, self.output_size]), name='weights')\n",
    "        self.b = tf.Variable(tf.random.normal([self.output_size]), name='bias')\n",
    "        self.is_built = True\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if not self.is_built:\n",
    "            self._build(x)\n",
    "        return self.activation(tf.matmul(x, self.W) + self.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dimension of the input is the \"batch\" dimension, which allows us to run many data through the model simultaneously. The matrix `W` has a row for each input dimension so that each column corresponds to the weights of one linear unit of the layer. After adding the bias vector to the vector resulting from the vector-matrix multiplication, we activate with a non-linearity.\n",
    "\n",
    "Let's define a simple, two layer network with this function. We activate the first layer with the rectified linear function [`tf.nn.relu`](https://www.tensorflow.org/api_docs/python/tf/nn/relu), but not the second layer so that we can interpret its output as the [logits](https://stackoverflow.com/questions/41455101/what-is-the-meaning-of-the-word-logits-in-tensorflow) of a discrete probability distribution. Note that we're going to flatten the data into a vector (784 = 28 x 28) so that we can use it with a linear layer (we encountered `tf.reshape` in the last hackathon). Loss is calculated with [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy), which implies that we're interpreting the output of the neural network as the paramters of a [categorical distribution](https://en.wikipedia.org/wiki/Categorical_distribution).\n",
    "\n",
    "Further, we'll train with minibatches of data with the for loop (using tqdm for a progress bar). We run the data forward in each minibatch, calculate the loss using the output logits and correct label, calculate gradients, and finally backprop gradients using the optimizer.apply_gradients() function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stepping into the code\n",
    "\n",
    "- We use batch size =1 i.e single image\n",
    "- pass it through the network (2-layer model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5, 1), dtype=uint8, numpy=\n",
       "array([[[252],\n",
       "        [163],\n",
       "        [ 38],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[253],\n",
       "        [255],\n",
       "        [228],\n",
       "        [ 44],\n",
       "        [  0]],\n",
       "\n",
       "       [[221],\n",
       "        [253],\n",
       "        [252],\n",
       "        [187],\n",
       "        [  7]],\n",
       "\n",
       "       [[150],\n",
       "        [253],\n",
       "        [252],\n",
       "        [252],\n",
       "        [116]],\n",
       "\n",
       "       [[249],\n",
       "        [253],\n",
       "        [252],\n",
       "        [252],\n",
       "        [240]]], dtype=uint8)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_img = batch['image'][idx] # examine raw image values. Notce the data type\n",
    "sample_img[15:20,15:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=3>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_lbl = batch['label'][idx]\n",
    "sample_lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5, 1), dtype=float32, numpy=\n",
       "array([[[0.9882353 ],\n",
       "        [0.6392157 ],\n",
       "        [0.14901961],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.99215686],\n",
       "        [1.        ],\n",
       "        [0.89411765],\n",
       "        [0.17254902],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.8666667 ],\n",
       "        [0.99215686],\n",
       "        [0.9882353 ],\n",
       "        [0.73333335],\n",
       "        [0.02745098]],\n",
       "\n",
       "       [[0.5882353 ],\n",
       "        [0.99215686],\n",
       "        [0.9882353 ],\n",
       "        [0.9882353 ],\n",
       "        [0.45490196]],\n",
       "\n",
       "       [[0.9764706 ],\n",
       "        [0.99215686],\n",
       "        [0.9882353 ],\n",
       "        [0.9882353 ],\n",
       "        [0.9411765 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_img = tf.cast(sample_img, tf.float32)/255.0 # normalizing image values\n",
    "sample_img[15:20,15:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer = Dense(200) # local Dense. Standard TF Dense class is tf.keras.layers.Dense()\n",
    "second_layer = Dense(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  (28, 28, 1)\n",
      "After:  (1, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"Before: \", sample_img.shape)\n",
    "sample_img = tf.reshape(sample_img, [-1, 784])\n",
    "print(\"After: \", sample_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 200])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fl_op = first_layer(sample_img) # batch size = 1\n",
    "fl_op.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([20.731482 ,  0.       ,  1.554097 ,  8.62453  ,  0.       ,\n",
       "        0.       ,  0.       ,  0.5419766,  0.       , 16.870516 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fl_op[0, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 10])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl_op = second_layer(fl_op)\n",
    "sl_op.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[ 0.       ,  0.       ,  0.       ,  0.       ,  2.7661428,\n",
       "         0.       , 66.65524  ,  0.       ,  0.       ,  0.       ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl_op \n",
    "# Logits are the unnormalized probabilities of the item belonging to a certain class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.1271866e-29 1.1271866e-29 1.1271866e-29 1.1271866e-29 1.7919125e-28\n",
      "  1.1271866e-29 1.0000000e+00 1.1271866e-29 1.1271866e-29 1.1271866e-29]], shape=(1, 10), dtype=float32)\n",
      "\n",
      "Sum of label probabilities is  1.0\n"
     ]
    }
   ],
   "source": [
    "probabilities = tf.nn.softmax(sl_op)\n",
    "print(probabilities)\n",
    "print(\"\")\n",
    "print(\"Sum of label probabilities is \", tf.reduce_sum(probabilities).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_pred_logits = tf.argmax(sl_op, axis=1)\n",
    "sample_pred_logits[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_pred_proba = tf.argmax(probabilities, axis=1)\n",
    "sample_pred_proba[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_lbl.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is sample == label?  tf.Tensor(False, shape=(), dtype=bool)\n",
      "\n",
      "Converting Bool to Float to allow summation:  tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "\n",
      "Accuracy over batch of 1 image:  0.0\n"
     ]
    }
   ],
   "source": [
    "# accuracy calc\n",
    "print(\"Is sample == label? \", tf.equal(sample_pred_logits[0], sample_lbl))\n",
    "print(\"\\nConverting Bool to Float to allow summation: \", tf.cast(tf.equal(sample_pred_logits[0], sample_lbl), tf.float32))\n",
    "# accuracy for batch size 1/ one image\n",
    "print(\"\\nAccuracy over batch of 1 image: \", tf.reduce_mean(tf.cast(tf.equal(sample_pred_logits[0], sample_lbl), tf.float32)).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.65524"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss calc\n",
    "\n",
    "# Measures the probability error in discrete classification tasks in which the \n",
    "# classes are mutually exclusive (each entry is in exactly one class).\n",
    "\n",
    "# This op expects unscaled logits, since it performs a softmax on logits internally for efficiency. \n",
    "# Do not call this op with the output of softmax, as it will produce incorrect results.\n",
    "\n",
    "sample_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=sl_op[0], labels=sample_lbl)\n",
    "sample_loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After reshaping input batch (32, 784)\n",
      "Label shape:  (32,)\n",
      "FL output shape:  (32, 200)\n",
      "SL output shape:  (32, 10)\n",
      "Loss shape:  (32,)\n",
      "Loss values shape:  1\n",
      "predictions:  (32,)\n",
      "accuracy:  (32,)\n",
      "Accuracy values shape:  1\n",
      "=================\n",
      "tf.Tensor([8 7 9 9 6 4 3 9 5 6 4 4 6 8 4 6 6 2 4 8 8 3 4 7 7 7 9 2 8 7 9 4], shape=(32,), dtype=int64)\n",
      "tf.Tensor([9 2 3 4 5 9 5 5 5 2 3 3 5 9 9 5 4 5 3 5 9 1 5 5 5 4 9 5 5 5 3 5], shape=(32,), dtype=int64)\n",
      "Batch accuracy:  0.0625\n",
      "\n",
      "Num. correct preds= 2.0, After dividing by batch size 32: 0.0625 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "first_layer = Dense(200)\n",
    "second_layer = Dense(10)\n",
    "\n",
    "loss_values = []\n",
    "accuracy_values = []\n",
    "\n",
    "for batch in tqdm(train_ds):\n",
    "    # run network\n",
    "    x = tf.reshape(tf.cast(batch['image'], tf.float32)/255., [-1, 784]) # -1 means everyting not otherwise accounted for\n",
    "    print(\"After reshaping input batch\", x.shape)\n",
    "    labels = batch['label']\n",
    "    print(\"Label shape: \", labels.shape)\n",
    "    x = first_layer(x)\n",
    "    print(\"FL output shape: \", x.shape)\n",
    "    logits = second_layer(x)\n",
    "    print(\"SL output shape: \", logits.shape)\n",
    "    \n",
    "    # calculate loss\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n",
    "    print(\"Loss shape: \", loss.shape)\n",
    "    loss_values.append(loss)\n",
    "    print(\"Loss values shape: \", len(loss_values))\n",
    "    \n",
    "    # calculate accuracy\n",
    "    predictions = tf.argmax(logits, axis=1)\n",
    "    print(\"predictions: \", predictions.shape)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predictions, labels), tf.float32))\n",
    "    print(\"accuracy: \", predictions.shape)\n",
    "    accuracy_values.append(accuracy)\n",
    "    print(\"Accuracy values shape: \", len(accuracy_values))\n",
    "    \n",
    "    print(\"=================\")\n",
    "    print(labels)\n",
    "    print(predictions)\n",
    "    print(\"Batch accuracy: \", np.mean(accuracy_values)) # 0.125*32 = 4\n",
    "    correct_preds = tf.math.reduce_sum(tf.cast(tf.equal(labels, predictions), tf.float32)).numpy()\n",
    "    print(\"\\nNum. correct preds= {}, After dividing by batch size 32: {} \".format(correct_preds, correct_preds/32.0 ))\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Orig code: Running batch through a small two layer model\n",
    "\n",
    "- Only forward pass\n",
    "- Only one batch = 32 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:01<00:00, 1005.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches parsed:  1875\n",
      "Accuracy: 0.14096667\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_layer = Dense(200)\n",
    "second_layer = Dense(10)\n",
    "\n",
    "loss_values = []\n",
    "accuracy_values = []\n",
    "# Loop through one epoch of data\n",
    "for batch in tqdm(train_ds):\n",
    "    # run network\n",
    "    x = tf.reshape(tf.cast(batch['image'], tf.float32), [-1, 784]) # -1 means everyting not otherwise accounted for\n",
    "    labels = batch['label']\n",
    "    x = first_layer(x)\n",
    "    logits = second_layer(x)\n",
    "    \n",
    "    # calculate loss\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n",
    "    loss_values.append(loss)\n",
    "    \n",
    "    # calculate accuracy\n",
    "    predictions = tf.argmax(logits, axis=1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predictions, labels), tf.float32))\n",
    "    accuracy_values.append(accuracy)\n",
    "    \n",
    "    \n",
    "print(\"Number of batches parsed: \", len(loss_values))\n",
    "\n",
    "# print accuracy\n",
    "print(\"Accuracy:\", np.mean(accuracy_values))\n",
    "# plot per-datum loss\n",
    "loss_values = np.concatenate(loss_values)\n",
    "plt.hist(loss_values, density=True, bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Training by minibatch/gradient step and epoch\n",
    "\n",
    "Now let's re-declare the network with pre-defined layers using [`tf.keras.layers.Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense), group the layers using [`tf.keras.Sequential`](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential), and training the parameters with the [`Adam`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) optimizer.\n",
    "\n",
    "Note how [`tf.GradientTape`](https://www.tensorflow.org/guide/autodiff) is used. We run all the computations which we want to backpropagate gradients through in the scope of the tape and then, after the loss is calculated, we can call `tape.gradient` to calculate the gradient of the output with respect to the model variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:06<00:00, 292.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (32, 200)                 157000    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (32, 10)                  2010      \n",
      "=================================================================\n",
      "Total params: 159,010\n",
      "Trainable params: 159,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Accuracy: 0.9321167\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using Sequential groups all the layers to run at once\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(200, tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10))\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "loss_values = []\n",
    "accuracy_values = []\n",
    "# Loop through one epoch of data\n",
    "for epoch in range(1):\n",
    "    for batch in tqdm(train_ds):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # run network\n",
    "            x = tf.reshape(tf.cast(batch['image'], tf.float32)/255.0, [-1, 784])\n",
    "            labels = batch['label']\n",
    "            logits = model(x)\n",
    "\n",
    "            # calculate loss\n",
    "            loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels)    \n",
    "        loss_values.append(loss)\n",
    "    \n",
    "        # gradient update\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    \n",
    "        # calculate accuracy\n",
    "        predictions = tf.argmax(logits, axis=1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(predictions, labels), tf.float32))\n",
    "        accuracy_values.append(accuracy)\n",
    "\n",
    "print(model.summary())\n",
    "    \n",
    "# accuracy\n",
    "print(\"Accuracy:\", np.mean(accuracy_values))\n",
    "# plot per-datum loss\n",
    "loss_values = np.concatenate(loss_values)\n",
    "plt.hist(loss_values, density=True, bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework\n",
    "\n",
    "Your homework is \n",
    "- to specify a network with `tf.keras.layers`, \n",
    "- train it on the MNIST dataset (as above, but with train/validation split), \n",
    "- use val split to avoid overfitting/ monitor training perf\n",
    "- use test split to report final model perf on unseen data\n",
    "- and try out 2 or 3 variations of different architectures. \n",
    "    - I.e., change the number of neurons or layers, \n",
    "    - change the activation function (you can find more in the documentation at [`tf.nn` (https://www.tensorflow.org/api_docs/python/tf/nn)), or even change the optimizer ([`tf.keras.optimizers`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)). \n",
    "    \n",
    "Write up a paragraph or two with your observations. E.g., \n",
    "- how did it affect the final accuracy on the validation data? \n",
    "- How did it affect the rate at which the model improved? Remember to add early stopping and increase the number of training epochs. \n",
    "\n",
    "**Submit a `.pdf` with the writeup and `.py` with the code.**\n",
    "\n",
    "I'm expecting this to take about an hour (or less if you're experienced). Feel free to use any code from this or previous hackathons. If you don't understand how to do any part of this or if it's taking you longer than that, please let me know in office hours or by email (both can be found on the syllabus). I'm also happy to discuss if you just want to ask more questions about anything in this notebook!\n",
    "\n",
    "### Coda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "# From Colah's Blog, linearly separating spirals with linear transforms and non-linearities\n",
    "# How does a neural network separate entangled data?\n",
    "print(\"We want the blue and red lines to be linearly separable, so how does a neural network manage to do this?\\\n",
    " Let's visualize the linear transformations and non-linearities.\")\n",
    "HTML('<img src=\"http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/img/spiral.1-2.2-2-2-2-2-2.gif\">')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP (tensorflow-env)",
   "language": "python",
   "name": "tensorflow-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
